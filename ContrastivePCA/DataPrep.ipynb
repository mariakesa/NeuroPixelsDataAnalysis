{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16cf644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa733566",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/media/maria/DATA1/Documents/NeuroMatchAcademy2020_dat/unzipped_files/Moniz_2017-05-15.tar/'\n",
    "trials_intervals = np.load(data_path+'/'+'trials.intervals.npy') # in seconds\n",
    "spike_times = np.load(data_path+'/'+'spikes.times.npy') * 1000\n",
    "spike_clusters = np.load(data_path+'/'+'spikes.clusters.npy')\n",
    "clusters_annotation = np.load(data_path+'/'+'clusters._phy_annotation.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2855888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_spikes(spike_times,spike_clusters, clusters_annotation, bin_size = 10):\n",
    "\n",
    "    # Using clusters._phy_annotation.npy obtain valid clusters (i.e. >= 2)\n",
    "    # valid_clusters_idx = np.array(np.where(clusters_annotation>=2))[0]\n",
    "\n",
    "    spike_time_cells = np.empty(len(clusters_annotation), dtype=object) # Initalise empty object\n",
    "    for i in (np.arange(len(np.unique(spike_clusters)))):\n",
    "      # Create a spike time arrays, where each array in the array is a spike time of a cell\n",
    "      spike_time_cells[i] = spike_times[(np.where(spike_clusters == i)[0])]\n",
    "\n",
    "    # Bin spike times into 10ms intervals\n",
    "    spike_time_binned = np.empty(len(np.unique(spike_clusters)), dtype=object) # Initalise empty object\n",
    "    sum_spikes = np.empty(len(np.unique(spike_clusters)), dtype=object) # Initalise empty object\n",
    "\n",
    "    for cell_num in np.arange(len(spike_time_cells)):\n",
    "        spike_time_hist = np.histogram(spike_time_cells[cell_num],bins = np.arange(0,np.floor(spike_time_cells[cell_num][-1]),bin_size))\n",
    "        spike_time_binned[cell_num] = spike_time_hist[0]\n",
    "        sum_spikes[cell_num] = np.sum(spike_time_binned[cell_num])\n",
    "\n",
    "    cell_spikes_max = np.argmax(sum_spikes) # cell with the maximum number of spikes for plotting purposes\n",
    "    # Spike_time_binned returns binned spikes sorted into cells\n",
    "    # Spike_time_cells returns UNbinned spikes sorted into cells\n",
    "    # cell_spikes_max returns a single cell index that has the max number of spikes (i.e most active cell)\n",
    "    return spike_time_binned, spike_time_cells, cell_spikes_max\n",
    "\n",
    "def sort_cells_trials(spike_time_binned,spike_time_cells, trials_intervals, bin_size = 10):\n",
    "    # Epoch duration is defined as the period after the visual stimulus\n",
    "\n",
    "    # Sort into trials\n",
    "    spike_time_binned_trial = np.empty(len(spike_time_binned), dtype=object)\n",
    "    for cell_num in np.arange(len(spike_time_binned)):\n",
    "        spike_time_binned_trial[cell_num] = np.empty(len(trials_intervals), dtype=object)\n",
    "\n",
    "        for i,trials_start_end in enumerate(trials_intervals):\n",
    "            # Sort spikes into their trial numbers.\n",
    "            spike_time_binned_trial[cell_num][i] = spike_time_binned[cell_num][ int(np.floor(trials_start_end[0]*(1000/bin_size))) : int(np.floor(trials_start_end[1]*(1000/bin_size)))]\n",
    "    \n",
    "    # spike_time_binned_trial returns spikes that are sorted into cells and trials\n",
    "    # spike_time_binned_trial_response returns spikes that are sorted into cells and trials, and spliced accordingly to desired epoch duration post-visual stim onset\n",
    "\n",
    "    return spike_time_binned_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f2948a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_time_binned, spike_time_cells, cell_spikes_max=bin_spikes(spike_times,spike_clusters, clusters_annotation,bin_size = 10)\n",
    "spike_time_binned_trial=sort_cells_trials(spike_time_binned,spike_time_cells, trials_intervals, bin_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cd9fc97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_time_binned_trial[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "019f7f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rates_for_trials(spike_time_binned_trial):\n",
    "    rates=[]\n",
    "    for trial in range(0,247):\n",
    "        lst=[]\n",
    "        for cell in range(spike_time_binned_trial.shape[0]):\n",
    "            lst.append(np.sum(spike_time_binned_trial[cell][trial])/(10*spike_time_binned_trial[cell][trial].shape[0]/1000))\n",
    "        rates.append(lst)\n",
    "    return rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ef666d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rates=get_rates_for_trials(spike_time_binned_trial)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2c7b791",
   "metadata": {},
   "source": [
    "rates=np.array(rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5658bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247, 806)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0995257d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isnan(rates)==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2305afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('rates_for_poisson.npy',rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35cf7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_for_pca(spike_time_binned_trial):\n",
    "    for_pca=[]\n",
    "    for trial in range(0,247):\n",
    "        lst=[]\n",
    "        for cell in range(spike_time_binned_trial.shape[0]):\n",
    "            lst.append(spike_time_binned_trial[cell][trial])\n",
    "        for_pca.append(lst)\n",
    "    return for_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0cff4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_pca=prep_data_for_pca(spike_time_binned_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "714a09dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_pca_get_features(for_pca):\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    pcs=[]\n",
    "    for trial in range(0,247):\n",
    "        print(trial)\n",
    "        pca=PCA(n_components=1)\n",
    "        pc=pca.fit_transform(np.array(for_pca[trial]))\n",
    "        pcs.append(pc.flatten())\n",
    "    pcs=np.array(pcs)\n",
    "    return pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22523db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n"
     ]
    }
   ],
   "source": [
    "pcs=conduct_pca_get_features(for_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
