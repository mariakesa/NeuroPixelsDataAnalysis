{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb1a30df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad6fa68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_spikes(spike_times,spike_clusters,clusters_annotation, bin_size = 10):\n",
    "\n",
    "    # Using clusters._phy_annotation.npy obtain valid clusters (i.e. >= 2)\n",
    "    # valid_clusters_idx = np.array(np.where(clusters_annotation>=2))[0]\n",
    "\n",
    "    spike_time_cells = np.empty(len(clusters_annotation), dtype=object) # Initalise empty object\n",
    "    for i in (np.arange(len(np.unique(spike_clusters)))):\n",
    "      # Create a spike time arrays, where each array in the array is a spike time of a cell\n",
    "      spike_time_cells[i] = spike_times[(np.where(spike_clusters == i)[0])]\n",
    "\n",
    "    # Bin spike times into 10ms intervals\n",
    "    spike_time_binned = np.empty(len(np.unique(spike_clusters)), dtype=object) # Initalise empty object\n",
    "    sum_spikes = np.empty(len(np.unique(spike_clusters)), dtype=object) # Initalise empty object\n",
    "\n",
    "    for cell_num in np.arange(len(spike_time_cells)):\n",
    "        spike_time_hist = np.histogram(spike_time_cells[cell_num],bins = np.arange(0,np.floor(spike_time_cells[cell_num][-1]),bin_size))\n",
    "        spike_time_binned[cell_num] = spike_time_hist[0][:5000]\n",
    "        sum_spikes[cell_num] = np.sum(spike_time_binned[cell_num])\n",
    "\n",
    "    cell_spikes_max = np.argmax(sum_spikes) # cell with the maximum number of spikes for plotting purposes\n",
    "\n",
    "    # Spike_time_binned returns binned spikes sorted into cells\n",
    "    # Spike_time_cells returns UNbinned spikes sorted into cells\n",
    "    # cell_spikes_max returns a single cell index that has the max number of spikes (i.e most active cell)\n",
    "    return spike_time_binned, spike_time_cells, cell_spikes_max\n",
    "\n",
    "def join(path):\n",
    "    dirs=os.listdir(path)\n",
    "    arr=[]\n",
    "    for d in dirs[:2]:\n",
    "        data_path=os.path.join(path,d)\n",
    "        spike_times = np.load(data_path+'/'+'spikes.times.npy')*1000 # Unbinned spike times in ms\n",
    "        clusters_annotation = np.load(data_path+'/'+'clusters._phy_annotation.npy')\n",
    "        spike_clusters = np.load(data_path+'/'+'spikes.clusters.npy')\n",
    "        spks=bin_spikes(spike_times,spike_clusters,clusters_annotation, bin_size = 10)[0]\n",
    "        for a in spks:\n",
    "            arr.append(a)\n",
    "    arr=np.array(arr)\n",
    "    return arr\n",
    "\n",
    "def sv(sv_path,arr):\n",
    "    np.save(sv_path,arr)\n",
    "    \n",
    "def proc(sv_path,path):\n",
    "    arr=join(path)\n",
    "    sv(sv_path,arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80bfe111",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/media/maria/DATA1/Documents/NeuroMatchAcademy2020_dat/unzipped_files/'\n",
    "sv_path='/media/maria/DATA1/Documents/NeuroMatchAcademy2020_dat/gan_spikes.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962085a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proc(sv_path,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324100a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spks=np.load(sv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
